
# SEIP

This repository contains code to run simulation experiments for the IEEE ITS 2023 paper titled "Simulation-based Design and Evaluation of
Infrastructure-based Collective Perception" by Ao Qu, Xuhuan Huang, Dajiang Suo


## Authors

- [@dajiangsuo](https://github.com/dajiangsuo)


# Overview

This repository contains code to run simulation experiments. It consists two parts. The first part ("Co-Simulation" folder), include files to run simulations in CARLA for infrastructure sensor deployment (we use LiDAR in our case study, but readers may modify our code to substitute LiDAR with other types of sensors) and generating synthetic point cloud. It was extended from the CARLA-SUMO co-simulation included in CARLA 9.13.  The second part (("" folder)) contains code for evaluating the effectiveness of sensor deployment solutions (e.g., location, height, configuration) through the lens of object detectgion. We leverage mmdetection3d (https://github.com/open-mmlab/mmdetection3d) and use the deep learning models (e.g., PointPillar) it provided for 3d object detection. Since CARLA and mmdetection3d use different coordinate systems, we have added new data preprocess files for coordinate transformation for the synthetic point cloud generated by CARLA.

To run the CARLA simulation for synthetic data generation, you will need to decied on the locations where infrastructure sensors are deployed. The integer programming algorithm we described in the paper can be used to find the optimal sensor delpoyment solutions, including recommended sensor deployment locations. We have implemented the algorithm in a python-based sensor deployment engine. The source code will be release soon at this website. 
## Part 1. Experiments on infrastructure LiDARs
You will need to download CARLA 9.13 and substitute the "Co-simulation" folder with the one (same name) we provided. To launch the simulation, you will need to launch CARLA server first and switch to the Town05 map (the map used in the case study in our paper).

```bash
  cd PythonAPI/util
  python config.py --map Town04
```

Afer the Town05 map is loaded, you may lauch a python client to deploy infra-sensors and generate point cloud data for downstream evaluation. 
```bash
  cd ~/carla/Co-Simulation/Sumo
  python cosim_infra.py examples/Town05.sumocfg  --sumo-gui
```

Note that the way to lauch the simulation is the same as the CARLA-SUMO co-simulation described on CARLA official website (https://carla.readthedocs.io/en/latest/adv_sumo/), except we have changed and rename the co-simulation file to "cosim_infra.py" to different it from the original file (i.e., run_synchronization.py).

You may modify the init function included in the cosim_infra.py file to add new or remove infrastructure LiDARs (or other types of sensors). 

In the case study presented in our paper, the infra-sensor locations are generated from the integer programming algorithm that we developed and implemented. The source code will be release soon on this website.
## Part 2. Evaluation of Infra-LiDAR performance on 3d object detection 

To run tests for evaluation performance, you will need to first download mmdetection3d and install it. We have provided a modified version that includes all the files needed for coordinate transformation (carla -> mmdetection3d) and 3d object detection by using PointPillar.

You will need to download the modified version of mmdetection3d at: https://github.com/huanx12/mmdet_carla and follow the instruction below for installation, training, and testing deep learning models for 3d object detection.

Assuming the project folder directory is called **mmdet_carla** 

- create an empty **data/carla** folder in mmdet_carla
- unzip the raw data zip file (e.g. **c16h35_numsensor1_opt.zip**) to ./data/carla
- create **ground truth data** (i.e. GT dataset) by the following cmd
```bash
  python tools/create_data.py carla \
		--root-path ./data/carla_raw/c16h35_numsensor1 \
		--out-dir ./data/carla/c16h35_numsensor1 \
		--fusion-type=0 \
		--workers 4
```
Now we have the preprocessed data for **training**, **testing**, and **visualization**

- add the previous **work_dirs** folder to mmdet_carla
- test the pre_trained model we have (e.g. epoch_300.pth) on ground truth data by cmd:
```bash
  python tools/test.py \
./work_dirs/c16h35_numsensor1/          hv_pointpillars_secfpn_6x8_160e_carla-3d-car_c16h35_numsensor1.py \
./work_dirs/c16h35_numsensor1/epoch_290.pth \
--eval mAP \
--out results.pkl
```

After testing, “results.pkl” is created in mmdet_carla, which will be called by ./tools/visualize_carla.py along with the grouth truth data
```bash
 python tools/visualize_carla.py --id 0 --srcs 0 
```


## License

[MIT](https://choosealicense.com/licenses/mit/)


## Acknowledgements

 - This work was partially supported by [MIT Mobility Initiative](https://www.mmi.mit.edu/)


## Citation
If you find this project useful in your research, please consider cite:

```bash
@article{qu2023seip,
  title={SEIP: Simulation-based Design and Evaluation of Infrastructure-based Collective Perception},
  author={Qu, Ao and Huang, Xuhuan and Suo, Dajiang},
  journal={arXiv preprint arXiv:2305.17892},
  year={2023}
}
```
## FAQ

#### Questions to the corresponding author djsuo@mit.edu

